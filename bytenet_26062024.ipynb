{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb90835381221e48",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Bytenet\n",
    "Implementation of the paper Neural Machine Translation in Linear Time (https://arxiv.org/pdf/1610.10099). The Bynet is a CNN based Encoder/Decoder Model used here for Sequence to Sequence Translation. The model is trained on a part of the WMT2014 english to german dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a8cb65fc8fc79",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Data Preprocessing\n",
    "Data is loaded and tokenized in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3a272ad06be98f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:10.065868100Z",
     "start_time": "2024-06-24T22:02:06.971808700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define Imports\n",
    "import json\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "import pickle\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:10.075311700Z",
     "start_time": "2024-06-24T22:02:10.068871Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "class WMT19JSONLoader:\n",
    "    def __init__(self, file_path, source_lang='de', target_lang='en', max_length=128):\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.max_length = max_length\n",
    "        # self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "        self.file_path = file_path\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\")\n",
    "\n",
    "    def load_json_data(self, file_path):\n",
    "        \"\"\"\n",
    "        Function that loads the downloaded JSON file\n",
    "\n",
    "        :param file_path:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        loaded_data = []\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    loaded_data.append(json.loads(line.strip()))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error when line is decoded: {e}\")\n",
    "        return loaded_data\n",
    "\n",
    "    def convert_to_tensor(self, src, trg):\n",
    "        \"\"\"\n",
    "        Checks if source and target are tensor\n",
    "        If both are not tensor, they are converted to tensors\n",
    "\n",
    "        :param src:\n",
    "        :param trg:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if not torch.is_tensor(src):\n",
    "            src = torch.Tensor(src)\n",
    "        if not torch.is_tensor(trg):\n",
    "            trg = torch.tensor(trg, dtype=torch.int32)\n",
    "        return src, trg\n",
    "\n",
    "    def extract_source_target(self, load_data):\n",
    "        \"\"\"\n",
    "        Function that extracts out of the downloaded JSON the\n",
    "        german rows as source and the english rows as targets\n",
    "\n",
    "        :param load_data:\n",
    "        :param source_lang:\n",
    "        :param target_lang:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        source_texts = []\n",
    "        target_texts = []\n",
    "        for item in load_data:\n",
    "            if ('row' in item and 'translation' in item['row'] and\n",
    "                    self.source_lang in item['row']['translation'] and\n",
    "                    self.target_lang in item['row']['translation']):\n",
    "                source_texts.append(item['row']['translation'][self.source_lang])\n",
    "                target_texts.append(item['row']['translation'][self.target_lang])\n",
    "        return source_texts, target_texts\n",
    "\n",
    "    def tokenize_texts(self, texts):\n",
    "        \"\"\"\n",
    "        Function for tokenizing the text data\n",
    "        Uses BERT-Tokenizer as tokenizer model\n",
    "\n",
    "        :param texts:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        tokenized_texts = []\n",
    "        for text in texts:\n",
    "            tokens = self.tokenizer(text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "            \n",
    "            tokenized_texts.append(tokens['input_ids'].squeeze())\n",
    "        return tokenized_texts\n",
    "\n",
    "    def load_and_tokenize(self, json_file_path):\n",
    "        \"\"\"\n",
    "        Function that does the load json data\n",
    "        and the tokenizing process\n",
    "\n",
    "        :param json_file_path:\n",
    "        \"\"\"\n",
    "        loaded_data = self.load_json_data(json_file_path)\n",
    "\n",
    "        source_texts, target_texts = self.extract_source_target(loaded_data)\n",
    "\n",
    "        # The tokenized source and targets\n",
    "        # self.tokenizer is a object of type transformers from the Bert model\n",
    "        # padding=\"max_length\": is used to fill sequence to maximal length\n",
    "        # truncation = True: Means that the sequence is cutted, if longer than max_length\n",
    "        # return_tensors=\"pt\": Means that a pytorch tensor is returned\n",
    "        # the source text is tokenized into smaller elements\n",
    "        tokenized_source_texts = self.tokenize_texts(source_texts)\n",
    "\n",
    "        # the target text is tokenized into smaller elements\n",
    "        tokenized_target_texts = self.tokenize_texts(target_texts)\n",
    "\n",
    "        #TODO: evetually squeeze as in WMTLoader\n",
    "\n",
    "        return tokenized_source_texts, tokenized_target_texts\n",
    "\n",
    "\n",
    "def download_data(offset, length):\n",
    "    \"\"\"\n",
    "    Method for downloading the dataset as JSON\n",
    "    F.e. if the first 10 rows have to be downloaded, offset has to\n",
    "    be 0 and length has to be 10\n",
    "\n",
    "    :param offset: The offset used in the url\n",
    "    :param length: The length of the selected number of rows in the dataset\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    url = f\"https://datasets-server.huggingface.co/rows?dataset=wmt%2Fwmt19&config=de-en&split=train&offset={offset}&length={length}\"\n",
    "    query_parameters = {\"downloadformat\": \"json\"}\n",
    "    response = requests.get(url, params=query_parameters)\n",
    "    if response.status_code == 200:\n",
    "        loaded_data = response.json()\n",
    "        print(f\"Downloading dataset-offset: {offset}\")\n",
    "        return loaded_data['rows']\n",
    "    else:\n",
    "        print(f\"Error while downloading data: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def save_data_to_json(load_data, file_path):\n",
    "    \"\"\"\n",
    "    Writes data into the JSON object\n",
    "\n",
    "    :param load_data: The data that has to be writen into file\n",
    "    :param file_path: The file path where the file has to be saved\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'a', encoding='utf-8') as f:\n",
    "        for item in load_data:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "def download_batch_and_save(offset, length, output_file):\n",
    "    \"\"\"\n",
    "    Downloads and saves the batch\n",
    "\n",
    "    :param offset: The offset which is currently used to download\n",
    "    :param length: The length is defined with 100\n",
    "    :param output_file: The name of the file to be saved\n",
    "    \"\"\"\n",
    "    loaded_data = download_data(offset, length)\n",
    "    save_data_to_json(loaded_data, output_file)\n",
    "\n",
    "\n",
    "def download_entire_de_en_dataset(batch_size, output_dir, num_workers):\n",
    "    \"\"\"\n",
    "    Downloads the entire WMT19 dataset. Uses a ThreadPoolExecutor for\n",
    "    faster download of the dataset.\n",
    "\n",
    "    :param batch_size:\n",
    "    :param output_dir:\n",
    "    :param num_workers:\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    output_file = os.path.join(output_dir, 'wmt_19_de_en.json')\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = []\n",
    "        while True:\n",
    "            futures.append(executor.submit(download_batch_and_save, offset, batch_size, output_file))\n",
    "            offset += batch_size\n",
    "            # if offset >= 34800000:\n",
    "            # This controls how much of the dataset is actually downloaded\n",
    "            if offset >= 40000:\n",
    "                break\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e56fee0d9e654",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### ByteNet Model\n",
    "The following Cells implement the necessary parts of the ByteNet model. The model is made up of a number of sets of, each of which contains a number of residual blocks that apply LayerNorm and 1D Convolutions, which is further masked for the Decoder part of the Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c87aa7aeddcd1c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:10.600276200Z",
     "start_time": "2024-06-24T22:02:10.072311600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports for ByteNet\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from Data.data_loader import WMTLoader, WMT19JSONLoader, download_entire_de_en_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b0836c6097c8f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:10.608697300Z",
     "start_time": "2024-06-24T22:02:10.603274200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlockReLu(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of residual Layer for Bytenet machine translation task.\n",
    "\n",
    "    :param d: The number of input features.\n",
    "    :param dilation: The initial dilation rate for the convolution layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, dilation, k, decoder=False):\n",
    "        super(ResidualBlockReLu, self).__init__()\n",
    "        self.decoder = decoder\n",
    "        self.layer_norm1 = nn.LayerNorm(128)\n",
    "        self.reLu1 = nn.ReLU()\n",
    "        # 2*d -> d\n",
    "        self.conv1 = nn.Conv1d(d * 2, d, 1)\n",
    "        self.layer_norm2 = nn.LayerNorm(128)\n",
    "        self.reLu2 = nn.ReLU()\n",
    "        # Masked kernel size is k\n",
    "        # Dilation only used for masked convolution\n",
    "        # d -> d\n",
    "        if decoder:\n",
    "            # Masked convolution basically means all padding on left side\n",
    "            self.receptive_field = (k - 1) * dilation\n",
    "            self.conv2 = nn.Conv1d(d, d, k, dilation=dilation)\n",
    "        else:\n",
    "            # Padding still needed to keep the size of the input and output the same\n",
    "            padding = (k - 1) * dilation // 2\n",
    "            if padding > 0:\n",
    "                self.conv2 = nn.Conv1d(d, d, k, dilation=dilation, padding=padding)\n",
    "            else:\n",
    "                self.conv2 = nn.Conv1d(d, d, k, dilation=dilation)\n",
    "        self.layer_norm3 = nn.LayerNorm(128)\n",
    "        self.reLu3 = nn.ReLU()\n",
    "        # d -> 2*d\n",
    "        self.conv3 = nn.Conv1d(d, d * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.reLu1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.reLu2(x)\n",
    "        # When Decoder is used, the convolution is causal\n",
    "        if self.decoder and self.receptive_field > 0:\n",
    "            x = F.pad(x, (self.receptive_field, 0))\n",
    "        x = self.conv2(x)\n",
    "        x = self.layer_norm3(x)\n",
    "        x = self.reLu3(x)\n",
    "        x = self.conv3(x)\n",
    "        # Add back the residual\n",
    "        x += residual\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e51d4e256313426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:10.610941400Z",
     "start_time": "2024-06-24T22:02:10.607696900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class BytenetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the ByteNet Encoder. Default Parameters are set to the ones used in the paper.\n",
    "    \n",
    "    :param kernel_size: The kernel size for the unmasked (padded) convolution in the residual block.\n",
    "    :param max_dilation_rate: The maximum dilation rate for the convolution layers.\n",
    "    :param masked_kernel_size: The kernel size for the masked convolution in the residual block (only interesting for decoder).\n",
    "    :param num_sets: The number of sets of residual blocks.\n",
    "    :param set_size: The number of residual blocks in each set.\n",
    "    :param hidden_channels: The number of hidden channels in the model.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size=3, max_dilation_rate=16, masked_kernel_size=3, num_sets=6, set_size=5,\n",
    "                 hidden_channels=800, emb_size = 1600):\n",
    "        super(BytenetEncoder, self).__init__()\n",
    "        self.num_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.layers = nn.Sequential()\n",
    "        # 128 is size of tokenizer\n",
    "        # input of shape [batch_size, 128, 128] as [batch_size, tokens, embedding_size]\n",
    "        self.layers.append(nn.Conv1d(in_channels=emb_size, out_channels=hidden_channels * 2, kernel_size=1))\n",
    "        # From the Paper:\n",
    "        # Model has a series of residual blocks of increased dilation rate\n",
    "        # With unmasked convolutions for the encoder\n",
    "        for _ in range(num_sets):\n",
    "            dilation_rate = 1\n",
    "            for _ in range(set_size):\n",
    "                # Dilation rate does not exceed a given maximum\n",
    "                # Example from the paper: 16\n",
    "                self.layers.append(ResidualBlockReLu(hidden_channels,\n",
    "                                                     dilation_rate if dilation_rate <= max_dilation_rate else max_dilation_rate,\n",
    "                                                     masked_kernel_size))\n",
    "                                # Dilation Rate doubles each layer (starting out at 1)\n",
    "                dilation_rate = dilation_rate * 2\n",
    "\n",
    "            # \"the network applies one more convolution\"\n",
    "        # Note: The output of the residual layers is 2*input_features, however the output of the final convolutions is not specified in the paper\n",
    "        # Experimentation needed if it should be 2*input_features or input_features\n",
    "        self.encoder_out_conv = nn.Conv1d(in_channels=hidden_channels * 2, out_channels=2 * hidden_channels, kernel_size=1)\n",
    "        # \"and ReLU\"\n",
    "        # Not sure if these last 2 layers should be in encoder or just decoder\n",
    "        # self.layers.append(nn.ReLU())\n",
    "        # \"followed by a convolution\"\n",
    "        # self.layers.append(nn.Conv1d(hidden_channels, hidden_channels, kernel_size))\n",
    "        # \"and a final softmax layer\" (probably not for encoder, however paper does not specify)\n",
    "        # self.layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Temporary\n",
    "        x = x.float()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.encoder_out_conv(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8c0481c8e2822a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:10.620760Z",
     "start_time": "2024-06-24T22:02:10.612940700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class BytenetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the ByteNet Decoder. Default Parameters are set to the ones used in the paper.\n",
    "    \n",
    "    :param kernel_size: The kernel size for the unmasked (padded) convolution in the residual block (not important for decoder).\n",
    "    :param max_dilation_rate: The maximum dilation rate for the convolution layers.\n",
    "    :param masked_kernel_size: The kernel size for the masked convolution in the residual block.\n",
    "    :param num_sets: The number of sets of residual blocks.\n",
    "    :param set_size: The number of residual blocks in each set.\n",
    "    :param hidden_channels: The number of hidden channels in the model.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size=3, max_dilation_rate=16, masked_kernel_size=3, num_sets=6, set_size=5,\n",
    "                 hidden_channels=800, output_channels=384):\n",
    "        super(BytenetDecoder, self).__init__()\n",
    "        self.num_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.layers = nn.Sequential()\n",
    "        # From the Paper:\n",
    "        # Model has a series of residual blocks of increased dilation rate\n",
    "        # With masekd convolution for decoder\n",
    "        for _ in range(num_sets):\n",
    "            dilation_rate = 1\n",
    "            for _ in range(set_size):\n",
    "                # Dilation Rate doubles each layer (starting out at 1)\n",
    "                # 1, 2, 4, 8, 16\n",
    "                # Dilation rate does not exceed a given maximum\n",
    "                # Example from the paper: 16\n",
    "                self.layers.append(ResidualBlockReLu(hidden_channels,\n",
    "                                                     dilation_rate if dilation_rate <= max_dilation_rate else max_dilation_rate,\n",
    "                                                     masked_kernel_size, decoder=True))\n",
    "                dilation_rate = dilation_rate * 2\n",
    "\n",
    "        # \"the network applies one more convolution\"\n",
    "        # Note: The output of the residual layers is 2*input_features, however the output of the final convolutions is not specified in the paper\n",
    "        # Experimentation needed if it should be 2*input_features or input_features\n",
    "        self.layers.append(nn.Conv1d(hidden_channels * 2, hidden_channels, 1))\n",
    "        # \"and ReLU\"\n",
    "        self.layers.append(nn.ReLU())\n",
    "        # \"followed by a convolution\"\n",
    "        self.layers.append(nn.Conv1d(hidden_channels, output_channels, 1))\n",
    "        # \"and a final softmax layer\"\n",
    "        # self.layers.append(nn.LogSoftmax(dim=-1))\n",
    "\n",
    "        # self.layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b840fe3aa4af1592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:10.628666800Z",
     "start_time": "2024-06-24T22:02:10.619760600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderStacking(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacks the encoder and decoder for the ByteNet model.\n",
    "    This means passing the output of the encoder as input to the decoder.\n",
    "    \n",
    "    :param kernel_size: The kernel size for the unmasked (padded) convolution in the residual block (for Encoder).\n",
    "    :param max_dilation_rate: The maximum dilation rate for the convolution layers.\n",
    "    :param masked_kernel_size: The kernel size for the masked convolution in the residual block (for Decoder).\n",
    "    :param num_sets: The number of sets of residual blocks.\n",
    "    :param set_size: The number of residual blocks in each set.\n",
    "    :param hidden_channels: The number of hidden channels in the model.\n",
    "    :param output_channels: The number of output channels in the model (vocab size).\n",
    "\n",
    "    :return x: The output of the decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size=3, max_dilation_rate=16, masked_kernel_size=3, n_sets=6, blocks_per_set=5,\n",
    "                 hidden_channels=800, output_channels = 384, emb_size= 1600):\n",
    "        super(EncoderDecoderStacking, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_size)\n",
    "        self.encoder = BytenetEncoder(kernel_size=kernel_size, max_dilation_rate=max_dilation_rate,\n",
    "                                      masked_kernel_size=masked_kernel_size, num_sets=n_sets, set_size=blocks_per_set,\n",
    "                                      hidden_channels=hidden_channels, emb_size=emb_size)\n",
    "        self.decoder = BytenetDecoder(kernel_size=kernel_size, max_dilation_rate=max_dilation_rate,\n",
    "                                      masked_kernel_size=masked_kernel_size, num_sets=n_sets, set_size=blocks_per_set,\n",
    "                                      hidden_channels=hidden_channels, output_channels=output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This permutation is needed for embeddings in pytorch with 1d convolutions\n",
    "        embed_x = self.embed(x).permute(0, 2, 1)\n",
    "        print(embed_x.shape)\n",
    "        x = self.encoder(embed_x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cd398c96893f06c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:10.628666800Z",
     "start_time": "2024-06-24T22:02:10.623263300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class InputEmbeddingTensor:\n",
    "    \"\"\"\n",
    "    Class which enables the embedding of tokens.\n",
    "\n",
    "    :param vocab_size: The size of the vocabulary as int.\n",
    "    :param embed_size: The size of the embedding units as int.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super(InputEmbeddingTensor, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        # This is the actual lookup table.\n",
    "        # A lookup table is an array of data that maps input values to output values\n",
    "        self.lookup_table_non_zero = nn.Embedding(vocab_size - 1, embed_size)\n",
    "        init.xavier_uniform_(self.lookup_table_non_zero.weight)\n",
    "\n",
    "    def embed(self, in_values):\n",
    "        \"\"\"\n",
    "        In this method the first n tokens are embedded via look-up table.\n",
    "        The n tokens serve as targets for the predictions.\n",
    "\n",
    "        :param in_values: The train input values from batch, more exact: the tokens\n",
    "        :return: A embedded tensor of size n × 2d where d is the number of inner\n",
    "                channels in the network\n",
    "        \"\"\"\n",
    "        lookup_table_zero = torch.zeros(1, self.embed_size).to(in_values.device)\n",
    "        # Here the both look up tables are combined. The rows with the zeros and the rows\n",
    "        # with values from the actual lookup table are combined therefore\n",
    "        lookup_table = torch.cat((lookup_table_zero, self.lookup_table_non_zero.weight.to(device)),\n",
    "                                 0)  # Move to the same device as inputs\n",
    "        # Next the input ids are embedded into the lookup table, which means that each id has it own\n",
    "        # embedding-vector, f.e:\n",
    "        # id: 5 => [1,5,4]; id:7 => [3,2,9]\n",
    "        # The input ids are the tokens\n",
    "        # If a token sequence of 5;7 is used, the resulting matrix is:\n",
    "        # [1,5,4],[3,2,9]\n",
    "        return F.embedding(in_values, lookup_table).to(in_values.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1948b0b0-69f6-4176-bec7-67b8a6f5a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchDecoder:\n",
    "    def __init__(self, model, beam_width, max_seq_len, start_token, end_token, device):\n",
    "        \"\"\"\n",
    "        Class which is used to generate the most likely output sequence given a set of possible outputs.\n",
    "\n",
    "        :param model: The model itself\n",
    "        :param beam width:\n",
    "        :param max_seq_len: \n",
    "        :param start_token: \n",
    "        :param end_token:\n",
    "        :param device:\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.beam_width = beam_width\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.device = device\n",
    "\n",
    "def decode(self, encoder_output):\n",
    "    \"\"\"\n",
    "    In this method the sequence with the highest score is returned\n",
    "    Beam search decoding is used to find the most likely translation \n",
    "    given a probabilistic model that scores the possible translations.\n",
    "\n",
    "    :param encoder_output: The encoder output as a letent representation\n",
    "    :return: A array of sequences\n",
    "    \"\"\"\n",
    "    # Initialize the start tokens with size (batch size, 1) and set them to the start token value\n",
    "    start_tokens = torch.full((encoder_output.size(0), 1), self.start_token, dtype=torch.long, device=self.device)\n",
    "    # Create a list of sequences consisting of a tuple (sequence, score).\n",
    "    # We start with the the start token and d score of 0\n",
    "    sequences = [(start_tokens, 0)] \n",
    "\n",
    "    # We iterate of the defined maximal sequence length\n",
    "    for _ in range(self.max_seq_len):\n",
    "        all_candidates = []\n",
    "        for seq, score in sequences:\n",
    "            # input to the decoder: embed the current sequence\n",
    "            # Embeddings represent real-world objects, like words, images etc and are embedded as vectors\n",
    "            decoder_input = self.model.embed(seq)\n",
    "            # The mode decoder now receives the embeddings\n",
    "            decoder_output = self.model.decoder(decoder_input)\n",
    "            \n",
    "            # Get the log probabilities of the last token\n",
    "            log_probs = F.log_softmax(decoder_output[:, -1, :], dim=-1)\n",
    "            # Using topk to get the receive the top k propabilities and the top k tokens\n",
    "            # That means we receive the propabilities with the highest value and their token\n",
    "            # And beam_width is used to get the beam_width topk propabilities\n",
    "            topk_log_probs, topk_tokens = log_probs.topk(self.beam_width)\n",
    "\n",
    "            # Now we iterate over the ktop propabilities and tokens, defined with the range beam_width\n",
    "            for i in range(self.beam_width):\n",
    "                candidate = (torch.cat([seq, topk_tokens[:, i].unsqueeze(1)], dim=1), score + topk_log_probs[:, i].item())\n",
    "                all_candidates.append(candidate)\n",
    "\n",
    "        # Sort all candidates by score and select the top beam_width ones\n",
    "        # Therefore reverse true\n",
    "        ordered = sorted(all_candidates, key=lambda x: x[1], reverse=True)\n",
    "        sequences = ordered[:self.beam_width]\n",
    "\n",
    "        # Check if the end token is among the sequences\n",
    "        # If so, we break the loop of range self.max_seq_len\n",
    "        if any(seq[0][:, -1] == self.end_token for seq, _ in sequences):\n",
    "            break\n",
    "\n",
    "    # Return the sequence with the highest score\n",
    "    return sequences[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c907c805a3bd6b0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Training\n",
    "The following cells implement the training of the ByteNet model. The model is trained on a part of the WMT2014 english to german dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70480f0620367b3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:11.498460900Z",
     "start_time": "2024-06-24T22:02:10.628666800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset-offset: 300\n",
      "Downloading dataset-offset: 200\n",
      "Downloading dataset-offset: 100\n",
      "Downloading dataset-offset: 0\n",
      "Downloading dataset-offset: 700\n",
      "Downloading dataset-offset: 600\n",
      "Downloading dataset-offset: 400\n",
      "Downloading dataset-offset: 500\n",
      "Downloading dataset-offset: 1000\n",
      "Downloading dataset-offset: 900\n",
      "Downloading dataset-offset: 800\n",
      "Downloading dataset-offset: 1100\n",
      "Downloading dataset-offset: 1400\n",
      "Downloading dataset-offset: 1500\n",
      "Downloading dataset-offset: 1200\n",
      "Downloading dataset-offset: 1300\n",
      "Downloading dataset-offset: 1800\n",
      "Downloading dataset-offset: 1700\n",
      "Downloading dataset-offset: 1600\n",
      "Downloading dataset-offset: 1900\n",
      "Downloading dataset-offset: 2000\n",
      "Downloading dataset-offset: 2200\n",
      "Downloading dataset-offset: 2300\n",
      "Downloading dataset-offset: 2100\n",
      "Downloading dataset-offset: 2400\n",
      "Downloading dataset-offset: 2500\n",
      "Downloading dataset-offset: 2600\n",
      "Downloading dataset-offset: 2800\n",
      "Downloading dataset-offset: 2700\n",
      "Downloading dataset-offset: 2900\n",
      "Downloading dataset-offset: 3000\n",
      "Downloading dataset-offset: 3300\n",
      "Downloading dataset-offset: 3100\n",
      "Downloading dataset-offset: 3400\n",
      "Downloading dataset-offset: 3200\n",
      "Downloading dataset-offset: 3600\n",
      "Downloading dataset-offset: 3700\n",
      "Downloading dataset-offset: 3500\n",
      "Downloading dataset-offset: 3800\n",
      "Downloading dataset-offset: 3900\n",
      "Downloading dataset-offset: 4000\n",
      "Downloading dataset-offset: 4200\n",
      "Downloading dataset-offset: 4100\n",
      "Downloading dataset-offset: 4300\n",
      "Downloading dataset-offset: 4400\n",
      "Downloading dataset-offset: 4500\n",
      "Downloading dataset-offset: 4600\n",
      "Downloading dataset-offset: 4700\n",
      "Downloading dataset-offset: 5000\n",
      "Downloading dataset-offset: 4900\n",
      "Downloading dataset-offset: 5100\n",
      "Downloading dataset-offset: 4800\n",
      "Downloading dataset-offset: 5200\n",
      "Downloading dataset-offset: 5300\n",
      "Downloading dataset-offset: 5400\n",
      "Downloading dataset-offset: 5600\n",
      "Downloading dataset-offset: 5500\n",
      "Downloading dataset-offset: 5700\n",
      "Downloading dataset-offset: 5800\n",
      "Downloading dataset-offset: 5900\n",
      "Downloading dataset-offset: 6000\n",
      "Downloading dataset-offset: 6100\n",
      "Downloading dataset-offset: 6400\n",
      "Downloading dataset-offset: 6300\n",
      "Downloading dataset-offset: 6200\n",
      "Downloading dataset-offset: 6500\n",
      "Downloading dataset-offset: 6600\n",
      "Downloading dataset-offset: 6700\n",
      "Downloading dataset-offset: 6800\n",
      "Downloading dataset-offset: 6900\n",
      "Downloading dataset-offset: 7000\n",
      "Downloading dataset-offset: 7300\n",
      "Downloading dataset-offset: 7100\n",
      "Downloading dataset-offset: 7400\n",
      "Downloading dataset-offset: 7200\n",
      "Downloading dataset-offset: 7500\n",
      "Downloading dataset-offset: 7600\n",
      "Downloading dataset-offset: 7700\n",
      "Downloading dataset-offset: 7800\n",
      "Downloading dataset-offset: 7900\n",
      "Downloading dataset-offset: 8000\n",
      "Downloading dataset-offset: 8100\n",
      "Downloading dataset-offset: 8200\n",
      "Downloading dataset-offset: 8500\n",
      "Downloading dataset-offset: 8300\n",
      "Downloading dataset-offset: 8600\n",
      "Downloading dataset-offset: 8400\n",
      "Downloading dataset-offset: 8700\n",
      "Downloading dataset-offset: 8900\n",
      "Downloading dataset-offset: 9000\n",
      "Downloading dataset-offset: 8800\n",
      "Downloading dataset-offset: 9100\n",
      "Downloading dataset-offset: 9200\n",
      "Downloading dataset-offset: 9300\n",
      "Downloading dataset-offset: 9400\n",
      "Downloading dataset-offset: 9500\n",
      "Downloading dataset-offset: 9700\n",
      "Downloading dataset-offset: 9600\n",
      "Downloading dataset-offset: 9800\n",
      "Downloading dataset-offset: 9900\n",
      "Downloading dataset-offset: 10000\n",
      "Downloading dataset-offset: 10200\n",
      "Downloading dataset-offset: 10300\n",
      "Downloading dataset-offset: 10100\n",
      "Downloading dataset-offset: 10400\n",
      "Downloading dataset-offset: 10500\n",
      "Downloading dataset-offset: 10600\n",
      "Downloading dataset-offset: 10700\n",
      "Downloading dataset-offset: 10900\n",
      "Downloading dataset-offset: 11100\n",
      "Downloading dataset-offset: 11000\n",
      "Downloading dataset-offset: 10800\n",
      "Downloading dataset-offset: 11200\n",
      "Downloading dataset-offset: 11300\n",
      "Downloading dataset-offset: 11400\n",
      "Downloading dataset-offset: 11600\n",
      "Downloading dataset-offset: 11800\n",
      "Downloading dataset-offset: 11700\n",
      "Downloading dataset-offset: 12000\n",
      "Downloading dataset-offset: 12100\n",
      "Downloading dataset-offset: 11900\n",
      "Downloading dataset-offset: 12200\n",
      "Downloading dataset-offset: 12300\n",
      "Downloading dataset-offset: 11500\n",
      "Downloading dataset-offset: 12500\n",
      "Downloading dataset-offset: 12700\n",
      "Downloading dataset-offset: 12400\n",
      "Downloading dataset-offset: 12800\n",
      "Downloading dataset-offset: 12600\n",
      "Downloading dataset-offset: 13000\n",
      "Downloading dataset-offset: 13100\n",
      "Downloading dataset-offset: 13200\n",
      "Downloading dataset-offset: 12900\n",
      "Downloading dataset-offset: 13300\n",
      "Downloading dataset-offset: 13500\n",
      "Downloading dataset-offset: 13600\n",
      "Downloading dataset-offset: 13400\n",
      "Downloading dataset-offset: 13800\n",
      "Downloading dataset-offset: 13900\n",
      "Downloading dataset-offset: 13700\n",
      "Downloading dataset-offset: 14000\n",
      "Downloading dataset-offset: 14100\n",
      "Downloading dataset-offset: 14200\n",
      "Downloading dataset-offset: 14300\n",
      "Downloading dataset-offset: 14400\n",
      "Downloading dataset-offset: 14500\n",
      "Downloading dataset-offset: 14700\n",
      "Downloading dataset-offset: 14600\n",
      "Downloading dataset-offset: 14900\n",
      "Downloading dataset-offset: 14800\n",
      "Downloading dataset-offset: 15100\n",
      "Downloading dataset-offset: 15000\n",
      "Downloading dataset-offset: 15200\n",
      "Downloading dataset-offset: 15300\n",
      "Downloading dataset-offset: 15400\n",
      "Downloading dataset-offset: 15500\n",
      "Downloading dataset-offset: 15600\n",
      "Downloading dataset-offset: 15700\n",
      "Downloading dataset-offset: 15800\n",
      "Downloading dataset-offset: 15900\n",
      "Downloading dataset-offset: 16000\n",
      "Downloading dataset-offset: 16100\n",
      "Downloading dataset-offset: 16200\n",
      "Downloading dataset-offset: 16300\n",
      "Downloading dataset-offset: 16400\n",
      "Downloading dataset-offset: 16500\n",
      "Downloading dataset-offset: 16700\n",
      "Downloading dataset-offset: 16800\n",
      "Downloading dataset-offset: 16600\n",
      "Downloading dataset-offset: 16900\n",
      "Downloading dataset-offset: 17000\n",
      "Downloading dataset-offset: 17100\n",
      "Downloading dataset-offset: 17200\n",
      "Downloading dataset-offset: 17300\n",
      "Downloading dataset-offset: 17400\n",
      "Downloading dataset-offset: 17500\n",
      "Downloading dataset-offset: 17700\n",
      "Downloading dataset-offset: 17600\n",
      "Downloading dataset-offset: 17800\n",
      "Downloading dataset-offset: 18000\n",
      "Downloading dataset-offset: 18100\n",
      "Downloading dataset-offset: 18200\n",
      "Downloading dataset-offset: 17900\n",
      "Downloading dataset-offset: 18300\n",
      "Downloading dataset-offset: 18400\n",
      "Downloading dataset-offset: 18500\n",
      "Downloading dataset-offset: 18600\n",
      "Downloading dataset-offset: 18700\n",
      "Downloading dataset-offset: 18800\n",
      "Downloading dataset-offset: 18900\n",
      "Downloading dataset-offset: 19000\n",
      "Downloading dataset-offset: 19100\n",
      "Downloading dataset-offset: 19200\n",
      "Downloading dataset-offset: 19400\n",
      "Downloading dataset-offset: 19300\n",
      "Downloading dataset-offset: 19600\n",
      "Downloading dataset-offset: 19700\n",
      "Downloading dataset-offset: 19500\n",
      "Downloading dataset-offset: 19800\n",
      "Downloading dataset-offset: 19900\n",
      "Downloading dataset-offset: 20000\n",
      "Downloading dataset-offset: 20100\n",
      "Downloading dataset-offset: 20200\n",
      "Downloading dataset-offset: 20400\n",
      "Downloading dataset-offset: 20500\n",
      "Downloading dataset-offset: 20600\n",
      "Downloading dataset-offset: 20300\n",
      "Downloading dataset-offset: 20700\n",
      "Downloading dataset-offset: 20800\n",
      "Downloading dataset-offset: 20900\n",
      "Downloading dataset-offset: 21000\n",
      "Downloading dataset-offset: 21100\n",
      "Downloading dataset-offset: 21300\n",
      "Downloading dataset-offset: 21400\n",
      "Downloading dataset-offset: 21200\n",
      "Downloading dataset-offset: 21500\n",
      "Downloading dataset-offset: 21800\n",
      "Downloading dataset-offset: 21700\n",
      "Downloading dataset-offset: 21600\n",
      "Downloading dataset-offset: 21900\n",
      "Downloading dataset-offset: 22100\n",
      "Downloading dataset-offset: 22200\n",
      "Downloading dataset-offset: 22300\n",
      "Downloading dataset-offset: 22000\n",
      "Downloading dataset-offset: 22500\n",
      "Downloading dataset-offset: 22600\n",
      "Downloading dataset-offset: 22700\n",
      "Downloading dataset-offset: 22400\n",
      "Downloading dataset-offset: 22800\n",
      "Downloading dataset-offset: 23000\n",
      "Downloading dataset-offset: 23100\n",
      "Downloading dataset-offset: 23200\n",
      "Downloading dataset-offset: 22900\n",
      "Downloading dataset-offset: 23300\n",
      "Downloading dataset-offset: 23400\n",
      "Downloading dataset-offset: 23500\n",
      "Downloading dataset-offset: 23600\n",
      "Downloading dataset-offset: 23700\n",
      "Downloading dataset-offset: 23800\n",
      "Downloading dataset-offset: 23900\n",
      "Downloading dataset-offset: 24000\n",
      "Downloading dataset-offset: 24200\n",
      "Downloading dataset-offset: 24100\n",
      "Downloading dataset-offset: 24400\n",
      "Downloading dataset-offset: 24300\n",
      "Downloading dataset-offset: 24500\n",
      "Downloading dataset-offset: 24600\n",
      "Downloading dataset-offset: 24700\n",
      "Downloading dataset-offset: 24900\n",
      "Downloading dataset-offset: 25000\n",
      "Downloading dataset-offset: 25100\n",
      "Downloading dataset-offset: 24800\n",
      "Downloading dataset-offset: 25300\n",
      "Downloading dataset-offset: 25400\n",
      "Downloading dataset-offset: 25500\n",
      "Downloading dataset-offset: 25200\n",
      "Downloading dataset-offset: 25600\n",
      "Downloading dataset-offset: 25700\n",
      "Downloading dataset-offset: 25800\n",
      "Downloading dataset-offset: 26000\n",
      "Downloading dataset-offset: 26100\n",
      "Downloading dataset-offset: 26200\n",
      "Downloading dataset-offset: 26300\n",
      "Downloading dataset-offset: 26400\n",
      "Downloading dataset-offset: 26500\n",
      "Downloading dataset-offset: 25900\n",
      "Downloading dataset-offset: 26600\n",
      "Downloading dataset-offset: 26700\n",
      "Downloading dataset-offset: 26800\n",
      "Downloading dataset-offset: 27000\n",
      "Downloading dataset-offset: 27100\n",
      "Downloading dataset-offset: 26900\n",
      "Downloading dataset-offset: 27200\n",
      "Downloading dataset-offset: 27300\n",
      "Downloading dataset-offset: 27400\n",
      "Downloading dataset-offset: 27500\n",
      "Downloading dataset-offset: 27600\n",
      "Downloading dataset-offset: 27700\n",
      "Downloading dataset-offset: 27800\n",
      "Downloading dataset-offset: 27900\n",
      "Downloading dataset-offset: 28000\n",
      "Downloading dataset-offset: 28100\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cache_dir = 'F:/wmt19_cache'\n",
    "#    wmt_loader = WMTLoader(split=\"train\", cache_dir=cache_dir)\n",
    "# Number of workers provides parallel loading\n",
    "num_workers = 4\n",
    "#    data_load = DataLoader(wmt_loader, batch_size=32, collate_fn=wmt_loader.collate_fn, num_workers=num_workers)\n",
    "#    temp = data_load\n",
    "#\n",
    "# for batch in wmt_loader:\n",
    "#     src_batch, tgt_batch = batch\n",
    "#     break\n",
    "\n",
    "batch_size = 100\n",
    "# change as needed\n",
    "output_dir = 'F:\\\\wmt19_json'\n",
    "download_entire_de_en_dataset(batch_size, output_dir, 4)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "wmt_json_loader = WMT19JSONLoader(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fee8a0b54625a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:11.507185700Z",
     "start_time": "2024-06-24T22:02:11.500765300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(wmt_json_loader.tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8377ed35cfd67f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:11.507185700Z",
     "start_time": "2024-06-24T22:02:11.503279600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "num_sets = 3\n",
    "set_size = 5\n",
    "embed_size = 1600 # Paper\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f1067395033b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:02:11.516540Z",
     "start_time": "2024-06-24T22:02:11.507716Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_texts, target_texts):\n",
    "        self.source_texts = source_texts\n",
    "        self.target_texts = target_texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.source_texts[idx], self.target_texts[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb4cf49e4c46a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:08:28.500479Z",
     "start_time": "2024-06-24T22:02:11.512456Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cache_dir = 'F:/wmt19_cache'\n",
    "# wmt_loader = WMTLoader(split=\"train\", cache_dir=cache_dir)\n",
    "# index = 0\n",
    "# source, target = wmt_loader[index]\n",
    "# print(\"Source:\", source)\n",
    "# print(\"Target:\", target)\n",
    "\n",
    "# use drive in which to save dataset in cache\n",
    "tokenized_source_texts, tokenized_target_texts = wmt_json_loader.load_and_tokenize(\n",
    "    'F:\\wmt19_json/wmt_19_de_en.json')\n",
    "src = tokenized_source_texts\n",
    "trgt = tokenized_target_texts\n",
    "vocab_size = len(wmt_json_loader.tokenizer.get_vocab())\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6107dbdf4562d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:08:28.506540Z",
     "start_time": "2024-06-24T22:08:28.501478600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(src[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe0d5915106d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:08:28.649352800Z",
     "start_time": "2024-06-24T22:08:28.507065100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(trgt[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832e3ebab290ddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:08:28.709194800Z",
     "start_time": "2024-06-24T22:08:28.653352300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "translation_dataset = TranslationDataset(tokenized_source_texts, tokenized_target_texts)\n",
    "dataset_size = len(translation_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(translation_dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102fd7de4aaea82a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T22:08:30.055279700Z",
     "start_time": "2024-06-24T22:08:28.701194800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "inputEmbedding = InputEmbeddingTensor(vocab_size, embed_size)\n",
    "# size and all params according to the paper, reduce for performance\n",
    "encoder_decoder = EncoderDecoderStacking(n_sets=3, blocks_per_set=5, output_channels=vocab_size,emb_size=embed_size).to(\n",
    "    device)\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "# When changing Loss function, make sure to check if the decoder should have the softmax layer, and adjust that\n",
    "optimizer = torch.optim.Adam(encoder_decoder.parameters(), lr=0.0003)  #  Paper: 0.0003\n",
    "# Number of epochs\n",
    "num_epochs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769f3ba23895957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T00:57:52.265545800Z",
     "start_time": "2024-06-24T22:08:30.055279700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    " # Train the model loop\n",
    " for epoch in range(1):\n",
    "    for i, (inputs, targets) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        # Move data to the appropriate device\n",
    "        # inputs = inputEmbedding.embed(inputs.to(device))  # Add batch dimension\n",
    "        inputs = inputs.to(device)  # Add batch\n",
    "        targets = targets.to(device)  # Add batch\n",
    "\n",
    "        outputs = encoder_decoder(inputs.to(device))\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss every 100 steps\n",
    "        if i % 25 == 0:\n",
    "            tqdm.write(\n",
    "            f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83fbc682708c15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T00:57:52.604399100Z",
     "start_time": "2024-06-25T00:57:52.208042900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "torch.save(encoder_decoder.state_dict(), 'model_state2.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b399dab3-275b-44d3-8755-65a3b1f8dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderStacking(n_sets=4, blocks_per_set=5, output_channels=vocab_size, emb_size=embed_size)\n",
    "model.load_state_dict(torch.load(model_260624.pth))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33f017-136d-4d99-ac9d-e21467debdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c404b-bc1d-4be4-acaf-a8af479913c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457b3d17cd13475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T01:04:26.164559800Z",
     "start_time": "2024-06-25T01:04:26.151042Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: I have no idea what I'm doing or if this is correct\n",
    "def translate(to_translate, model, loader):\n",
    "    model.eval()\n",
    "    inp = loader.tokenize_texts([to_translate])[0].unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        inp = inp.to(device)\n",
    "        encoder_output = model.encoder(inp)\n",
    "        encoder_output = encoder_output.to(device)\n",
    "        decoded_sequence = beam_search_decoder.decode(encoder_output)\n",
    "    print(decoded_sequence.shape)\n",
    "\n",
    "    token_ids = decoded_sequence.squeeze(0).tolist()\n",
    "    translated_texts = loader.tokenizer.decode(token_ids)\n",
    "\n",
    "    print(f\"Translated text: {translated_texts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879cfe2-bf96-4bb6-af41-aac7084705b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_val_loss = 0\n",
    "with torch.inference_mode():\n",
    "  for i, (inputs, targets) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)  \n",
    "    targets = targets.to(device)\n",
    "    print(inputs.shape)\n",
    "    encoder_output = model.encoder(inputs)\n",
    "    decoder_output = beam_search_decoder.decode(encoder_output)\n",
    "    \n",
    "    # loss\n",
    "    loss = criterion(decoder_output, targets)\n",
    "    total_val_loss += loss.item()\n",
    "  avg_val_loss = total_val_loss / len(test_loader)\n",
    "  tqdm.write(f'Validation Loss: {avg_val_loss}')\n",
    "  writer.add_scalar('Loss/val', avg_val_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0ce0d46bc04c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T01:08:23.738972100Z",
     "start_time": "2024-06-25T01:08:23.473870700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "encoder_decoder.eval()\n",
    "text = [\"Wir brauchen einen neuen Datensatz.\"]\n",
    "print(f\"Translating: {text}\")\n",
    "translate(text, encoder_decoder, wmt_json_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
